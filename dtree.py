#!/usr/bin/env python
"""kritik3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wdk2GUDgz9lWl10Q36Q8bnWk_Z48w_i0
"""

!pip install scikit-learn scipy

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import mean_squared_error, r2_score

df = pd.read_excel("cleaned.xlsx")

df['InvoiceNo'].dtype

data = df

data['target'] = data['CustomerID'].duplicated(keep=False).astype(int)

data = data.drop(columns=['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12'], errors='ignore')

# data.head()

# Create 'count_cancel' column based on the condition
data['count_cancel'] = (data['InvoiceNo'].str.startswith('C', na=False)).astype(int)

# Calculate the sum within each group of 'CustomerID'
data['count_cancel'] = data.groupby('CustomerID')['count_cancel'].transform('sum')

data_without_C = data[~data['InvoiceNo'].str.startswith('C', na=False)]

data_time = data_without_C[['CustomerID', 'InvoiceDate']].copy()

data_time['days_since_last_purchase'] = data_time.groupby('CustomerID')['InvoiceDate'].diff().dt.days

data_time.fillna(0, inplace=True)

data_time['max_days_since_last_purchase'] = data_time.groupby('CustomerID')['days_since_last_purchase'].transform('max')

# Calculate the mean frequency of orders for each 'id'
data_time['order_frequency_mean'] = data_time.groupby(['CustomerID', 'InvoiceDate'])['CustomerID'].transform('count')
data_time['order_frequency_mean'] = data_time.groupby('CustomerID')['order_frequency_mean'].transform('mean')

data_time = data_time[['CustomerID', 'max_days_since_last_purchase', 'order_frequency_mean']].drop_duplicates(subset='CustomerID')

data_value = data_without_C[['CustomerID', 'Quantity', 'UnitPrice', 'PurchaseAmount']].copy()

data_value = data_value.groupby('CustomerID').agg({
    'Quantity': 'mean',
    'UnitPrice': 'mean',
    'PurchaseAmount': 'mean'
}).reset_index()

# Rename columns for clarity
data_value.columns = ['CustomerID', 'MeanQuantity', 'MeanUnitPrice', 'MeanPurchaseAmount']

data_customer = pd.merge(data_value, data_time, on='CustomerID', how='inner')

data_customer = pd.merge(data_customer, data_without_C, on='CustomerID', how='left').drop_duplicates(subset='CustomerID')

data_customer = data_customer[['CustomerID', 'MeanQuantity', 'MeanUnitPrice',
       'MeanPurchaseAmount', 'max_days_since_last_purchase',
       'order_frequency_mean', 'Country', 'count_cancel', 'target']].copy()

# data_customer

data_with_C = data[data['InvoiceNo'].str.startswith('C', na=False)].copy()

data_with_C['days_since_last_cancel'] = data_with_C.groupby('CustomerID')['InvoiceDate'].diff().dt.days

data_with_C.fillna(0, inplace=True)

data_with_C['max_days_since_last_cancel'] = data_with_C.groupby('CustomerID')['days_since_last_cancel'].transform('max')

# Calculate the median frequency of orders for each 'id'
data_with_C['cancel_frequency_mean'] = data_with_C.groupby(['CustomerID', 'InvoiceDate'])['CustomerID'].transform('count')
data_with_C['cancel_frequency_mean'] = data_with_C.groupby('CustomerID')['cancel_frequency_mean'].transform('mean')

data_with_C = data_with_C[['CustomerID','max_days_since_last_cancel', 'cancel_frequency_mean']].copy()

data_customer = pd.merge(data_customer, data_with_C, how = 'outer', on = 'CustomerID').drop_duplicates(subset='CustomerID')

data_customer.fillna(0, inplace=True)

data_customer = pd.get_dummies(data_customer, columns=['Country'], prefix='Country')

# Select features (excluding 'target') and target variable
X = data_customer.drop(columns=['target'])  # Exclude the 'target' column
y = data_customer['target']  # Target variable

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize the linear regression model
linear_model = LinearRegression()

# Fit the model on the training data
linear_model.fit(X_train, y_train)

# Predict the target variable on the test set
y_pred = linear_model.predict(X_test)

# Convert predicted values to binary (0 or 1) using a threshold (e.g., 0.5)
y_pred_binary = (y_pred >= 0.5).astype(int)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred_binary)
conf_matrix = confusion_matrix(y_test, y_pred_binary)
class_report = classification_report(y_test, y_pred_binary)

# Print the evaluation metrics
print(f'Accuracy: {accuracy:.4f}')
print('Confusion Matrix:\n', conf_matrix)
print('Classification Report:\n', class_report)

# Create a logistic regression model
model = LogisticRegression()

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

# Display the evaluation metrics
print(f'Accuracy: {accuracy:.4f}')
print(f'Confusion Matrix:\n{conf_matrix}')
print(f'Classification Report:\n{classification_rep}')

# Split the data into features (X) and target variable (y)
X = data_customer[['MeanQuantity',
       'order_frequency_mean']]  # Features
y = data_customer['MeanPurchaseAmount']  # Target variable

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a linear regression model
model = LinearRegression()

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Display the evaluation metrics
print(f'Mean Squared Error: {mse:.4f}')
print(f'R-squared: {r2:.4f}')
